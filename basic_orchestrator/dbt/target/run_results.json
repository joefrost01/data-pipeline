{"metadata": {"dbt_schema_version": "https://schemas.getdbt.com/dbt/run-results/v6.json", "dbt_version": "1.10.15", "generated_at": "2025-12-13T23:58:14.815112Z", "invocation_id": "9a5fc011-4180-4ca7-a3f1-43156d99958f", "invocation_started_at": "2025-12-13T23:58:14.059052Z", "env": {}}, "results": [{"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.487506Z", "completed_at": "2025-12-13T23:58:14.489733Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.502700Z", "completed_at": "2025-12-13T23:58:14.545298Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.06791090965270996, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.stg_load_metadata", "compiled": true, "compiled_code": "\n\n\n\nwith source as (\n    select * from \"dev\".\"main\".\"load_metadata\"\n),\n\n-- Extract components from filename using regex\nparsed as (\n    select\n        load_id,\n        filename,\n        table_name,\n        row_count,\n        started_at,\n        completed_at as loaded_at,\n        \n        -- Extract feed name: everything before _YYYYMMDD or .csv\n        -- Pattern: strip date patterns and extensions\n        \n        regexp_replace(\n            regexp_replace(filename, '_\\d{8}.*\\.csv$', ''),\n            '\\.csv$', ''\n        ) as feed_name,\n        \n        -- Extract business date if present (YYYYMMDD pattern)\n        case\n            when regexp_matches(filename, '_(\\d{8})')\n            then strptime(regexp_extract(filename, '_(\\d{8})', 1), '%Y%m%d')::date\n            else (completed_at::date - interval '1 day')::date  -- T-1 fallback\n        end as business_date\n        \n        \n        \n    from source\n),\n\n-- Add version ranking within feed + business_date\nwith_version as (\n    select\n        *,\n        row_number() over (\n            partition by feed_name, business_date\n            order by loaded_at asc\n        ) as load_sequence,\n        \n        row_number() over (\n            partition by feed_name, business_date\n            order by loaded_at desc\n        ) as reverse_sequence\n        \n    from parsed\n)\n\nselect\n    load_id,\n    filename,\n    table_name,\n    row_count,\n    started_at,\n    loaded_at,\n    feed_name,\n    business_date,\n    load_sequence,\n    reverse_sequence = 1 as is_latest_for_business_date\n    \nfrom with_version", "relation_name": "\"dev\".\"main_staging\".\"stg_load_metadata\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.484797Z", "completed_at": "2025-12-13T23:58:14.489538Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.489903Z", "completed_at": "2025-12-13T23:58:14.554597Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.07556319236755371, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_date", "compiled": true, "compiled_code": "\n\n\n\n\n\n-- DuckDB: Use generate_series\nwith date_spine as (\n    select date_day::date as date_day\n    from generate_series(\n        date '2020-01-01',\n        date '2030-12-31',\n        interval '1 day'\n    ) as t(date_day)\n)\n\n\n\nselect\n    -- Natural key (YYYYMMDD)\n    \n  \n    cast(strftime(date_day, '%Y%m%d') as bigint)\n  \n as date_key,\n    \n    -- Date value\n    date_day as date_utc,\n    \n    -- Calendar attributes\n    \n    extract(year from date_day)::int as year,\n    extract(quarter from date_day)::int as quarter,\n    extract(month from date_day)::int as month,\n    extract(day from date_day)::int as day_of_month,\n    extract(dow from date_day)::int as day_of_week,\n    extract(week from date_day)::int as iso_week,\n    extract(dow from date_day) in (0, 6) as is_weekend\n    \n\nfrom date_spine", "relation_name": "\"dev\".\"main_marts\".\"dim_date\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.480440Z", "completed_at": "2025-12-13T23:58:14.496212Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.514572Z", "completed_at": "2025-12-13T23:58:14.563616Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.08438611030578613, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_time", "compiled": true, "compiled_code": "\n\n\n\n\n\n-- DuckDB: Generate series\nwith seconds as (\n    select generate_series::integer as second_of_day\n    from generate_series(0, 86399)\n)\n\n\n\nselect\n    -- Natural key (HHMMSS)\n    \n    cast(\n        lpad(cast(second_of_day // 3600 as varchar), 2, '0') ||\n        lpad(cast((second_of_day % 3600) // 60 as varchar), 2, '0') ||\n        lpad(cast(second_of_day % 60 as varchar), 2, '0')\n        as bigint\n    ) as time_key,\n    \n    -- Time components\n    second_of_day // 3600 as hour,\n    (second_of_day % 3600) // 60 as minute,\n    second_of_day % 60 as second\n    \n\nfrom seconds", "relation_name": "\"dev\".\"main_marts\".\"dim_time\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.555406Z", "completed_at": "2025-12-13T23:58:14.561550Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.561790Z", "completed_at": "2025-12-13T23:58:14.573093Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.01851797103881836, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.stg_futures_order_events", "compiled": true, "compiled_code": "\n\n\n\nwith source as (\n    select * from \"dev\".\"main\".\"raw_futures_order_events\"\n),\n\nload_meta as (\n    select * from \"dev\".\"main_staging\".\"stg_load_metadata\"\n),\n\ntyped as (\n    select\n        -- Event identification\n        \n  \n    try_cast(event_timestamp as timestamp)\n  \n as event_timestamp_utc,\n        \n  \n    try_cast(event_seq as integer)\n  \n as event_seq,\n        event_type,\n        order_status,\n        \n        -- Order identifiers\n        order_id,\n        nullif(parent_order_id, '') as parent_order_id,\n        client_order_id,\n        broker_order_id,\n        exchange_order_id,\n        \n        -- Organisation\n        account_id,\n        trader_id,\n        desk,\n        book,\n        \n        -- Strategy / source\n        strategy_id,\n        source_system,\n        \n        -- Instrument\n        symbol,\n        exchange,\n        product_type,\n        contract_month,\n        currency,\n        \n  \n    try_cast(multiplier as integer)\n  \n as multiplier,\n        \n  \n    try_cast(tick_size as numeric)\n  \n as tick_size,\n        \n        -- Order parameters\n        side,\n        order_type,\n        time_in_force,\n        \n  \n    try_cast(quantity as integer)\n  \n as quantity,\n        \n  \n    try_cast(limit_price as numeric)\n  \n as limit_price,\n        \n  \n    try_cast(stop_price as numeric)\n  \n as stop_price,\n        \n        -- Market data at event time\n        \n  \n    try_cast(best_bid as numeric)\n  \n as best_bid,\n        \n  \n    try_cast(best_ask as numeric)\n  \n as best_ask,\n        \n  \n    try_cast(mid_price as numeric)\n  \n as mid_price,\n        \n  \n    try_cast(spread as numeric)\n  \n as spread,\n        \n        -- Fill information\n        \n  \n    try_cast(filled_quantity as integer)\n  \n as filled_quantity,\n        \n  \n    try_cast(remaining_quantity as integer)\n  \n as remaining_quantity,\n        \n  \n    try_cast(last_fill_qty as integer)\n  \n as last_fill_qty,\n        \n  \n    try_cast(last_fill_price as numeric)\n  \n as last_fill_price,\n        \n  \n    try_cast(avg_fill_price as numeric)\n  \n as avg_fill_price,\n        \n        -- Risk\n        pre_trade_risk_check,\n        nullif(risk_limit_id, '') as risk_limit_id,\n        \n  \n    try_cast(current_position as integer)\n  \n as current_position,\n        \n  \n    try_cast(max_position_limit as integer)\n  \n as max_position_limit,\n        nullif(reject_reason, '') as reject_reason,\n        \n        -- Load tracking\n        src._load_id,\n        src._extra,\n        \n        -- Bi-temporal context from load metadata\n        lm.loaded_at,\n        lm.feed_name,\n        lm.business_date,\n        lm.is_latest_for_business_date\n        \n    from source src\n    left join load_meta lm on src._load_id = lm.load_id\n)\n\nselect * from typed", "relation_name": "\"dev\".\"main_staging\".\"stg_futures_order_events\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.583984Z", "completed_at": "2025-12-13T23:58:14.586802Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.588699Z", "completed_at": "2025-12-13T23:58:14.691870Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.11608600616455078, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_extra", "compiled": true, "compiled_code": "\n\n\n\n\n\nselect\n    \n  \n    \n    (hash(concat_ws('|', _extra)) & 9223372036854775807)::bigint\n  \n as extra_sk,\n    _extra\nfrom (\n    select distinct _extra\n    from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n    where _extra is not null\n\n    \n    and _extra not in (select _extra from \"dev\".\"main_marts\".\"dim_extra\" where extra_sk != -1)\n    \n) new_extras", "relation_name": "\"dev\".\"main_marts\".\"dim_extra\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.579944Z", "completed_at": "2025-12-13T23:58:14.587113Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.603153Z", "completed_at": "2025-12-13T23:58:14.697646Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.12396383285522461, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_order", "compiled": true, "compiled_code": "\n\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n),\n\n-- Get order attributes from the NEW event (first event for each order)\norder_creation as (\n    select\n        order_id,\n        parent_order_id,\n        client_order_id,\n        broker_order_id,\n        exchange_order_id,\n        side,\n        order_type,\n        time_in_force,\n        quantity,\n        limit_price,\n        stop_price,\n        strategy_id,\n        source_system,\n        event_timestamp_utc as created_at_utc,\n        row_number() over (partition by order_id order by event_seq) as rn\n    from events\n    where event_type = 'NEW'\n),\n\nnew_orders as (\n    select\n        order_id,\n        parent_order_id,\n        client_order_id,\n        broker_order_id,\n        exchange_order_id,\n        side,\n        order_type,\n        time_in_force,\n        quantity,\n        limit_price,\n        stop_price,\n        strategy_id,\n        source_system,\n        created_at_utc\n    from order_creation\n    where rn = 1\n),\n\nfinal as (\n    select\n        -- Surrogate key\n        \n  \n    \n    (hash(concat_ws('|', order_id)) & 9223372036854775807)::bigint\n  \n as order_sk,\n        \n        -- Business key and identifiers\n        order_id,\n        parent_order_id,\n        client_order_id,\n        broker_order_id,\n        exchange_order_id,\n        \n        -- Order parameters (immutable)\n        side,\n        order_type,\n        time_in_force,\n        quantity,\n        limit_price,\n        stop_price,\n        \n        -- Routing\n        strategy_id,\n        source_system\n        \n    from new_orders\n    \n    \n    -- Only insert orders we haven't seen before\n    where order_id not in (select order_id from \"dev\".\"main_marts\".\"dim_order\")\n    \n)\n\nselect * from final", "relation_name": "\"dev\".\"main_marts\".\"dim_order\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.609044Z", "completed_at": "2025-12-13T23:58:14.641745Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.642336Z", "completed_at": "2025-12-13T23:58:14.727070Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.11930513381958008, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_account", "compiled": true, "compiled_code": "\n\n\n\nwith  __dbt__cte__int_account_current as (\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n),\n\ndistinct_accounts as (\n    select\n        account_id,\n        min(event_timestamp_utc) as first_seen_utc,\n        max(event_timestamp_utc) as last_seen_utc\n    from events\n    group by account_id\n),\n\nfinal as (\n    select\n        -- Business key\n        account_id as account_bk,\n        \n        -- Surrogate key\n        \n  \n    \n    (hash(concat_ws('|', account_id, first_seen_utc)) & 9223372036854775807)::bigint\n  \n as account_sk,\n        \n        -- Attributes\n        account_id,\n        \n        -- Effective timestamp\n        first_seen_utc as effective_ts\n        \n    from distinct_accounts\n)\n\nselect * from final\n), staged as (\n    select * from __dbt__cte__int_account_current\n)\n\n\n\n\n\n\n  \n\n\n\n-- Incremental run: Insert new/changed records, close old versions\n\n-- New records and updated versions\nselect\n    source.account_sk,\n    source.account_bk,\n    \n    source.account_id,\n    \n    source.effective_ts as valid_from_utc,\n    \n  \n    '9999-12-31 23:59:59'::timestamp\n  \n as valid_to_utc,\n    true as is_current\nfrom staged as source\nleft join \"dev\".\"main_marts\".\"dim_account\" as existing\n    on source.account_bk = existing.account_bk\n    and existing.is_current = true\nwhere\n    -- New business key (no existing current record)\n    existing.account_bk is null\n    -- Or attributes have changed\n    or (coalesce(cast(source.account_id as varchar), '') != coalesce(cast(existing.account_id as varchar), ''))\n\nunion all\n\n-- Existing current records that need to be closed (attributes changed)\nselect\n    existing.account_sk,\n    existing.account_bk,\n    \n    existing.account_id,\n    \n    existing.valid_from_utc,\n    source.effective_ts as valid_to_utc,  -- Close at the time of change\n    false as is_current\nfrom \"dev\".\"main_marts\".\"dim_account\" as existing\ninner join staged as source\n    on source.account_bk = existing.account_bk\nwhere\n    existing.is_current = true\n    and (coalesce(cast(source.account_id as varchar), '') != coalesce(cast(existing.account_id as varchar), ''))\n\n\n", "relation_name": "\"dev\".\"main_marts\".\"dim_account\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.624272Z", "completed_at": "2025-12-13T23:58:14.644460Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.645190Z", "completed_at": "2025-12-13T23:58:14.736160Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.1276710033416748, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_instrument", "compiled": true, "compiled_code": "\n\n\n\nwith  __dbt__cte__int_instrument_current as (\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n),\n\n-- Get latest values for each instrument\nranked as (\n    select\n        exchange,\n        symbol,\n        contract_month,\n        product_type,\n        currency,\n        multiplier,\n        tick_size,\n        event_timestamp_utc,\n        row_number() over (\n            partition by exchange, symbol, contract_month\n            order by event_timestamp_utc desc\n        ) as rn\n    from events\n),\n\nlatest_values as (\n    select\n        exchange,\n        symbol,\n        contract_month,\n        product_type,\n        currency,\n        multiplier,\n        tick_size\n    from ranked\n    where rn = 1\n),\n\nwith_timestamps as (\n    select\n        lv.*,\n        e.first_seen_utc\n    from latest_values lv\n    inner join (\n        select\n            exchange,\n            symbol,\n            contract_month,\n            min(event_timestamp_utc) as first_seen_utc\n        from events\n        group by exchange, symbol, contract_month\n    ) e\n        on lv.exchange = e.exchange\n        and lv.symbol = e.symbol\n        and lv.contract_month = e.contract_month\n),\n\nfinal as (\n    select\n        -- Business key (colon-delimited as per spec)\n        exchange || ':' || symbol || ':' || contract_month as instrument_bk,\n        \n        -- Surrogate key\n        \n  \n    \n    (hash(concat_ws('|', exchange, symbol, contract_month, first_seen_utc)) & 9223372036854775807)::bigint\n  \n as instrument_sk,\n        \n        -- Composite identifier for convenience\n        exchange || ':' || symbol || ':' || contract_month as instrument_id,\n        \n        -- Attributes\n        symbol,\n        exchange,\n        product_type,\n        contract_month,\n        currency,\n        multiplier,\n        tick_size,\n        \n        -- Effective timestamp\n        first_seen_utc as effective_ts\n        \n    from with_timestamps\n)\n\nselect * from final\n), staged as (\n    select * from __dbt__cte__int_instrument_current\n)\n\n\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n  \n\n\n\n-- Incremental run: Insert new/changed records, close old versions\n\n-- New records and updated versions\nselect\n    source.instrument_sk,\n    source.instrument_bk,\n    \n    source.instrument_id,\n    \n    source.symbol,\n    \n    source.exchange,\n    \n    source.product_type,\n    \n    source.contract_month,\n    \n    source.currency,\n    \n    source.multiplier,\n    \n    source.tick_size,\n    \n    source.effective_ts as valid_from_utc,\n    \n  \n    '9999-12-31 23:59:59'::timestamp\n  \n as valid_to_utc,\n    true as is_current\nfrom staged as source\nleft join \"dev\".\"main_marts\".\"dim_instrument\" as existing\n    on source.instrument_bk = existing.instrument_bk\n    and existing.is_current = true\nwhere\n    -- New business key (no existing current record)\n    existing.instrument_bk is null\n    -- Or attributes have changed\n    or (coalesce(cast(source.instrument_id as varchar), '') != coalesce(cast(existing.instrument_id as varchar), '') or coalesce(cast(source.symbol as varchar), '') != coalesce(cast(existing.symbol as varchar), '') or coalesce(cast(source.exchange as varchar), '') != coalesce(cast(existing.exchange as varchar), '') or coalesce(cast(source.product_type as varchar), '') != coalesce(cast(existing.product_type as varchar), '') or coalesce(cast(source.contract_month as varchar), '') != coalesce(cast(existing.contract_month as varchar), '') or coalesce(cast(source.currency as varchar), '') != coalesce(cast(existing.currency as varchar), '') or coalesce(cast(source.multiplier as varchar), '') != coalesce(cast(existing.multiplier as varchar), '') or coalesce(cast(source.tick_size as varchar), '') != coalesce(cast(existing.tick_size as varchar), ''))\n\nunion all\n\n-- Existing current records that need to be closed (attributes changed)\nselect\n    existing.instrument_sk,\n    existing.instrument_bk,\n    \n    existing.instrument_id,\n    \n    existing.symbol,\n    \n    existing.exchange,\n    \n    existing.product_type,\n    \n    existing.contract_month,\n    \n    existing.currency,\n    \n    existing.multiplier,\n    \n    existing.tick_size,\n    \n    existing.valid_from_utc,\n    source.effective_ts as valid_to_utc,  -- Close at the time of change\n    false as is_current\nfrom \"dev\".\"main_marts\".\"dim_instrument\" as existing\ninner join staged as source\n    on source.instrument_bk = existing.instrument_bk\nwhere\n    existing.is_current = true\n    and (coalesce(cast(source.instrument_id as varchar), '') != coalesce(cast(existing.instrument_id as varchar), '') or coalesce(cast(source.symbol as varchar), '') != coalesce(cast(existing.symbol as varchar), '') or coalesce(cast(source.exchange as varchar), '') != coalesce(cast(existing.exchange as varchar), '') or coalesce(cast(source.product_type as varchar), '') != coalesce(cast(existing.product_type as varchar), '') or coalesce(cast(source.contract_month as varchar), '') != coalesce(cast(existing.contract_month as varchar), '') or coalesce(cast(source.currency as varchar), '') != coalesce(cast(existing.currency as varchar), '') or coalesce(cast(source.multiplier as varchar), '') != coalesce(cast(existing.multiplier as varchar), '') or coalesce(cast(source.tick_size as varchar), '') != coalesce(cast(existing.tick_size as varchar), ''))\n\n\n", "relation_name": "\"dev\".\"main_marts\".\"dim_instrument\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.700920Z", "completed_at": "2025-12-13T23:58:14.712572Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.714526Z", "completed_at": "2025-12-13T23:58:14.753862Z"}], "thread_id": "Thread-3 (worker)", "execution_time": 0.05443000793457031, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_org", "compiled": true, "compiled_code": "\n\n\n\nwith  __dbt__cte__int_org_current as (\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n),\n\n-- Derive division from desk (as agreed)\nwith_derived as (\n    select\n        desk,\n        book,\n        'Commercial Markets' as legal_entity,\n        case desk\n            when 'Commodities' then 'FICC'\n            when 'Rates' then 'FICC'\n            when 'Macro' then 'FICC'\n            when 'Equities' then 'EQUITIES'\n            else 'OTHER'\n        end as division,\n        min(event_timestamp_utc) as first_seen_utc,\n        max(event_timestamp_utc) as last_seen_utc\n    from events\n    group by desk, book\n),\n\n-- Build business key and surrogate key\nfinal as (\n    select\n        -- Business key (pipe-delimited for readability)\n        legal_entity || '|' || division || '|' || desk || '|' || book as org_bk,\n        \n        -- Surrogate key\n        \n  \n    \n    (hash(concat_ws('|', legal_entity, division, desk, book, first_seen_utc)) & 9223372036854775807)::bigint\n  \n as org_sk,\n        \n        -- Attributes\n        legal_entity,\n        division,\n        desk,\n        book,\n        \n        -- Effective timestamp (first time we saw this combination)\n        first_seen_utc as effective_ts\n        \n    from with_derived\n)\n\nselect * from final\n), staged as (\n    select * from __dbt__cte__int_org_current\n)\n\n\n\n\n\n\n  \n\n  \n\n  \n\n  \n\n\n\n-- Incremental run: Insert new/changed records, close old versions\n\n-- New records and updated versions\nselect\n    source.org_sk,\n    source.org_bk,\n    \n    source.legal_entity,\n    \n    source.division,\n    \n    source.desk,\n    \n    source.book,\n    \n    source.effective_ts as valid_from_utc,\n    \n  \n    '9999-12-31 23:59:59'::timestamp\n  \n as valid_to_utc,\n    true as is_current\nfrom staged as source\nleft join \"dev\".\"main_marts\".\"dim_org\" as existing\n    on source.org_bk = existing.org_bk\n    and existing.is_current = true\nwhere\n    -- New business key (no existing current record)\n    existing.org_bk is null\n    -- Or attributes have changed\n    or (coalesce(cast(source.legal_entity as varchar), '') != coalesce(cast(existing.legal_entity as varchar), '') or coalesce(cast(source.division as varchar), '') != coalesce(cast(existing.division as varchar), '') or coalesce(cast(source.desk as varchar), '') != coalesce(cast(existing.desk as varchar), '') or coalesce(cast(source.book as varchar), '') != coalesce(cast(existing.book as varchar), ''))\n\nunion all\n\n-- Existing current records that need to be closed (attributes changed)\nselect\n    existing.org_sk,\n    existing.org_bk,\n    \n    existing.legal_entity,\n    \n    existing.division,\n    \n    existing.desk,\n    \n    existing.book,\n    \n    existing.valid_from_utc,\n    source.effective_ts as valid_to_utc,  -- Close at the time of change\n    false as is_current\nfrom \"dev\".\"main_marts\".\"dim_org\" as existing\ninner join staged as source\n    on source.org_bk = existing.org_bk\nwhere\n    existing.is_current = true\n    and (coalesce(cast(source.legal_entity as varchar), '') != coalesce(cast(existing.legal_entity as varchar), '') or coalesce(cast(source.division as varchar), '') != coalesce(cast(existing.division as varchar), '') or coalesce(cast(source.desk as varchar), '') != coalesce(cast(existing.desk as varchar), '') or coalesce(cast(source.book as varchar), '') != coalesce(cast(existing.book as varchar), ''))\n\n\n", "relation_name": "\"dev\".\"main_marts\".\"dim_org\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.717068Z", "completed_at": "2025-12-13T23:58:14.727236Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.727654Z", "completed_at": "2025-12-13T23:58:14.758239Z"}], "thread_id": "Thread-1 (worker)", "execution_time": 0.04407787322998047, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.dim_trader", "compiled": true, "compiled_code": "\n\n\n\nwith  __dbt__cte__int_trader_current as (\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n),\n\ndistinct_traders as (\n    select\n        trader_id,\n        min(event_timestamp_utc) as first_seen_utc,\n        max(event_timestamp_utc) as last_seen_utc\n    from events\n    group by trader_id\n),\n\nfinal as (\n    select\n        -- Business key\n        trader_id as trader_bk,\n        \n        -- Surrogate key (includes first_seen for SCD2 versioning)\n        \n  \n    \n    (hash(concat_ws('|', trader_id, first_seen_utc)) & 9223372036854775807)::bigint\n  \n as trader_sk,\n        \n        -- Attributes\n        trader_id,\n        cast(null as varchar) as trader_name,  -- No reference data available\n        'HUMAN' as trader_type,                 -- Default as specified\n        \n        -- Effective timestamp\n        first_seen_utc as effective_ts\n        \n    from distinct_traders\n)\n\nselect * from final\n), staged as (\n    select * from __dbt__cte__int_trader_current\n)\n\n\n\n\n\n\n  \n\n  \n\n  \n\n\n\n-- Incremental run: Insert new/changed records, close old versions\n\n-- New records and updated versions\nselect\n    source.trader_sk,\n    source.trader_bk,\n    \n    source.trader_id,\n    \n    source.trader_name,\n    \n    source.trader_type,\n    \n    source.effective_ts as valid_from_utc,\n    \n  \n    '9999-12-31 23:59:59'::timestamp\n  \n as valid_to_utc,\n    true as is_current\nfrom staged as source\nleft join \"dev\".\"main_marts\".\"dim_trader\" as existing\n    on source.trader_bk = existing.trader_bk\n    and existing.is_current = true\nwhere\n    -- New business key (no existing current record)\n    existing.trader_bk is null\n    -- Or attributes have changed\n    or (coalesce(cast(source.trader_id as varchar), '') != coalesce(cast(existing.trader_id as varchar), '') or coalesce(cast(source.trader_name as varchar), '') != coalesce(cast(existing.trader_name as varchar), '') or coalesce(cast(source.trader_type as varchar), '') != coalesce(cast(existing.trader_type as varchar), ''))\n\nunion all\n\n-- Existing current records that need to be closed (attributes changed)\nselect\n    existing.trader_sk,\n    existing.trader_bk,\n    \n    existing.trader_id,\n    \n    existing.trader_name,\n    \n    existing.trader_type,\n    \n    existing.valid_from_utc,\n    source.effective_ts as valid_to_utc,  -- Close at the time of change\n    false as is_current\nfrom \"dev\".\"main_marts\".\"dim_trader\" as existing\ninner join staged as source\n    on source.trader_bk = existing.trader_bk\nwhere\n    existing.is_current = true\n    and (coalesce(cast(source.trader_id as varchar), '') != coalesce(cast(existing.trader_id as varchar), '') or coalesce(cast(source.trader_name as varchar), '') != coalesce(cast(existing.trader_name as varchar), '') or coalesce(cast(source.trader_type as varchar), '') != coalesce(cast(existing.trader_type as varchar), ''))\n\n\n", "relation_name": "\"dev\".\"main_marts\".\"dim_trader\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.759902Z", "completed_at": "2025-12-13T23:58:14.765064Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.765236Z", "completed_at": "2025-12-13T23:58:14.799366Z"}], "thread_id": "Thread-2 (worker)", "execution_time": 0.040060997009277344, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.fact_futures_order_event", "compiled": true, "compiled_code": "\n\n\n\nwith events as (\n    select * from \"dev\".\"main_staging\".\"stg_futures_order_events\"\n    \n    where _load_id not in (select distinct _load_id from \"dev\".\"main_marts\".\"fact_futures_order_event\")\n    \n),\n\n-- Build dimensional keys for joining\nwith_keys as (\n    select\n        e.*,\n        \n        -- Event business key (identifies unique real-world event)\n        e.order_id || '|' || cast(e.event_seq as varchar) as event_bk,\n        \n        -- Surrogate key includes loaded_at for bi-temporal versioning\n        \n  \n    \n    (hash(concat_ws('|', e.order_id, e.event_seq, e.loaded_at)) & 9223372036854775807)::bigint\n  \n as fact_event_sk,\n        \n        -- Extra dimension key (-1 if no schema drift)\n        case\n            when e._extra is not null then \n  \n    \n    (hash(concat_ws('|', e._extra)) & 9223372036854775807)::bigint\n  \n\n            else cast(-1 as bigint)\n        end as extra_sk,\n\n        -- Date and time keys\n        \n  \n    cast(strftime(e.event_timestamp_utc, '%Y%m%d') as bigint)\n  \n as date_key,\n        \n  \n    cast(strftime(e.event_timestamp_utc, '%H%M%S') as bigint)\n  \n as time_key,\n        \n  \n    cast(epoch_ms(e.event_timestamp_utc) % 1000 as bigint)\n  \n as event_millis,\n\n        -- Build business keys for dimension lookups\n        'Commercial Markets' || '|' ||\n        case e.desk\n            when 'Commodities' then 'FICC'\n            when 'Rates' then 'FICC'\n            when 'Macro' then 'FICC'\n            when 'Equities' then 'EQUITIES'\n            else 'OTHER'\n        end || '|' || e.desk || '|' || e.book as org_bk,\n\n        e.trader_id as trader_bk,\n        e.account_id as account_bk,\n        e.exchange || ':' || e.symbol || ':' || e.contract_month as instrument_bk\n\n    from events e\n),\n\n-- Join to dimensions\nwith_dimensions as (\n    select\n        k.fact_event_sk,\n        k.event_bk,\n        k.date_key,\n        k.time_key,\n        k.event_millis,\n        k.event_timestamp_utc,\n\n        -- Bi-temporal fields: new rows start as \"current\"\n        k.loaded_at as valid_from_utc,\n        \n  \n    '9999-12-31 23:59:59'::timestamp\n  \n as valid_to_utc,\n        true as is_current,\n        k.business_date,\n\n        -- Order dimension (Type 1 - simple join)\n        o.order_sk,\n        k.event_seq,\n\n        -- SCD2 dimension lookups (current version)\n        org.org_sk,\n        t.trader_sk,\n        a.account_sk,\n        i.instrument_sk,\n\n        -- Extra dimension (sparse, for schema drift)\n        k.extra_sk,\n\n        -- Event attributes\n        k.event_type,\n        k.order_status,\n\n        -- Fill information\n        k.filled_quantity,\n        k.remaining_quantity,\n        k.last_fill_qty,\n        k.last_fill_price,\n        k.avg_fill_price,\n\n        -- Market context\n        k.best_bid,\n        k.best_ask,\n        k.mid_price,\n        k.spread,\n\n        -- Risk information\n        k.pre_trade_risk_check,\n        k.risk_limit_id,\n        k.current_position,\n        k.max_position_limit,\n        k.reject_reason,\n\n        -- Lineage\n        k._load_id,\n        k.feed_name\n\n    from with_keys k\n\n    -- Order dimension\n    left join \"dev\".\"main_marts\".\"dim_order\" o\n        on k.order_id = o.order_id\n\n    -- Org dimension (SCD2 - join to current)\n    left join \"dev\".\"main_marts\".\"dim_org\" org\n        on k.org_bk = org.org_bk\n        and org.is_current = true\n\n    -- Trader dimension (SCD2)\n    left join \"dev\".\"main_marts\".\"dim_trader\" t\n        on k.trader_bk = t.trader_bk\n        and t.is_current = true\n\n    -- Account dimension (SCD2)\n    left join \"dev\".\"main_marts\".\"dim_account\" a\n        on k.account_bk = a.account_bk\n        and a.is_current = true\n\n    -- Instrument dimension (SCD2)\n    left join \"dev\".\"main_marts\".\"dim_instrument\" i\n        on k.instrument_bk = i.instrument_bk\n        and i.is_current = true\n)\n\nselect\n    -- Surrogate key\n    fact_event_sk,\n\n    -- Business key\n    event_bk,\n\n    -- Bi-temporal fields\n    valid_from_utc,\n    valid_to_utc,\n    is_current,\n    business_date,\n\n    -- Dimensional keys\n    order_sk,\n    event_seq,\n    date_key,\n    time_key,\n    event_millis,\n    event_timestamp_utc,\n    org_sk,\n    trader_sk,\n    account_sk,\n    instrument_sk,\n    extra_sk,\n\n    -- Event\n    event_type,\n    order_status,\n\n    -- Fills\n    filled_quantity,\n    remaining_quantity,\n    last_fill_qty,\n    last_fill_price,\n    avg_fill_price,\n\n    -- Market\n    best_bid,\n    best_ask,\n    mid_price,\n    spread,\n\n    -- Risk\n    pre_trade_risk_check,\n    risk_limit_id,\n    current_position,\n    max_position_limit,\n    reject_reason,\n\n    -- Lineage\n    _load_id,\n    feed_name\n\nfrom with_dimensions", "relation_name": "\"dev\".\"main_marts\".\"fact_futures_order_event\"", "batch_results": null}, {"status": "success", "timing": [{"name": "compile", "started_at": "2025-12-13T23:58:14.801151Z", "completed_at": "2025-12-13T23:58:14.802802Z"}, {"name": "execute", "started_at": "2025-12-13T23:58:14.802961Z", "completed_at": "2025-12-13T23:58:14.811786Z"}], "thread_id": "Thread-4 (worker)", "execution_time": 0.011155128479003906, "adapter_response": {"_message": "OK"}, "message": "OK", "failures": null, "unique_id": "model.surveillance.fact_futures_order_event_current", "compiled": true, "compiled_code": "\n\n\n\nselect\n    fact_event_sk,\n    event_bk,\n    business_date,\n    \n    -- Dimensional keys\n    order_sk,\n    event_seq,\n    date_key,\n    time_key,\n    event_millis,\n    event_timestamp_utc,\n    org_sk,\n    trader_sk,\n    account_sk,\n    instrument_sk,\n    extra_sk,\n    \n    -- Event\n    event_type,\n    order_status,\n    \n    -- Fills\n    filled_quantity,\n    remaining_quantity,\n    last_fill_qty,\n    last_fill_price,\n    avg_fill_price,\n    \n    -- Market\n    best_bid,\n    best_ask,\n    mid_price,\n    spread,\n    \n    -- Risk\n    pre_trade_risk_check,\n    risk_limit_id,\n    current_position,\n    max_position_limit,\n    reject_reason,\n    \n    -- Lineage (latest load)\n    _load_id,\n    feed_name,\n    valid_from_utc as loaded_at\n\nfrom \"dev\".\"main_marts\".\"fact_futures_order_event\"\nwhere is_current = true", "relation_name": "\"dev\".\"main_marts\".\"fact_futures_order_event_current\"", "batch_results": null}], "elapsed_time": 0.40331482887268066, "args": {"source_freshness_run_project_hooks": true, "partial_parse": true, "printer_width": 80, "project_dir": "/Users/josephfrost/code/data-pipeline/basic_orchestrator/dbt", "require_batched_execution_for_custom_microbatch_strategy": false, "require_resource_names_without_spaces": true, "vars": {}, "send_anonymous_usage_stats": true, "skip_nodes_if_on_run_start_fails": false, "state_modified_compare_vars": false, "introspect": true, "strict_mode": false, "partial_parse_file_diff": true, "require_yaml_configuration_for_mf_time_spines": false, "version_check": true, "print": true, "which": "run", "log_file_max_bytes": 10485760, "empty": false, "macro_debugging": false, "state_modified_compare_more_unrendered_values": false, "use_fast_test_edges": false, "warn_error_options": {"error": [], "warn": [], "silence": []}, "indirect_selection": "eager", "use_colors_file": true, "favor_state": false, "defer": false, "quiet": false, "require_explicit_package_overrides_for_builtin_materializations": true, "show_all_deprecations": false, "profiles_dir": ".", "log_level_file": "debug", "log_path": "/Users/josephfrost/code/data-pipeline/basic_orchestrator/dbt/logs", "use_colors": true, "static_parser": true, "log_level": "info", "show_resource_report": false, "invocation_command": "dbt run --no-fail-fast --profiles-dir .", "write_json": true, "require_generic_test_arguments_property": true, "log_format_file": "debug", "log_format": "default", "select": [], "require_nested_cumulative_type_params": false, "require_all_warnings_handled_by_warn_error": false, "exclude": [], "validate_macro_args": false, "populate_cache": true, "upload_to_artifacts_ingest_api": false, "cache_selected_only": false}}